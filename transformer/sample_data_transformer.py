"""Sample Data Transformer - Batch processing transformation

Transforms sample data generated by SampleDataGeneratorExtractor.
Maintains symmetry with Flink transformers but for batch processing.
"""
import json
from datetime import datetime, timezone
from typing import Iterator, Dict, Any, List
from transformer.base_transformer import AbstractTransformer


class SampleDataTransformer(AbstractTransformer):
    """Transforms sample data batches with enrichments
    
    Applies transformations to sample data similar to Flink transformers
    but in batch mode. Maintains architectural symmetry.
    """
    
    def __init__(self, add_processing_time: bool = True, 
                 enrich_url_patterns: bool = True):
        """Initialize batch transformer
        
        Args:
            add_processing_time: Add processing timestamp to each record
            enrich_url_patterns: Add URL pattern classification flags
        """
        self.add_processing_time = add_processing_time
        self.enrich_url_patterns = enrich_url_patterns

    def transform_single_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """Transform a single message with enrichments
        
        Args:
            message: Original message from sample data generator
            
        Returns:
            Transformed message with additional fields
        """
        # Start with original message
        transformed = message.copy()
        
        # Add processing time if requested
        if self.add_processing_time:
            transformed["processing_timestamp"] = datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')
        
        # Extract and promote hot keys (similar to Flink optimized transformer)
        transformed["msg"] = message["attributes"].get("msg", "")
        transformed["url"] = message["attributes"].get("url", "")  
        transformed["mobile"] = message["attributes"].get("mobile", "")
        
        # Add data quality flags
        body = message.get("body", "")
        transformed["is_valid_json"] = 1 if (body and body.strip().startswith('{') and body.strip().endswith('}')) else 0
        transformed["has_data_mobile"] = 1 if (body and '"data"' in body and '"mobile"' in body) else 0
        
        # Add URL pattern flags if requested
        if self.enrich_url_patterns:
            url = message["attributes"].get("url", "")
            transformed["is_getotp_url"] = 1 if "/auth/v3/getOtp" in url else 0
            transformed["is_api_url"] = 1 if "/api/" in url else 0
            transformed["is_payment_url"] = 1 if "/payments/" in url else 0
            transformed["is_health_url"] = 1 if "/health/" in url else 0
        
        # Add time-based fields for partitioning compatibility
        timestamp_str = message.get("timestamp", "")
        if timestamp_str:
            transformed["log_date"] = timestamp_str[:10]  # YYYY-MM-DD
            if len(timestamp_str) >= 13:
                hour_str = timestamp_str[11:13]
                try:
                    transformed["log_hour"] = int(hour_str)
                except ValueError:
                    transformed["log_hour"] = 0
            else:
                transformed["log_hour"] = 0
        else:
            transformed["log_date"] = ""
            transformed["log_hour"] = 0
            
        return transformed

    def transform(self, data: Iterator[List[Dict[str, Any]]]) -> Iterator[List[Dict[str, Any]]]:
        """Transform batches of sample data
        
        Args:
            data: Iterator of message batches from extractor
            
        Yields:
            Transformed batches with enriched data
        """
        print("ðŸ”„ Starting batch transformation...")
        
        batch_count = 0
        for batch in data:
            batch_count += 1
            transformed_batch = []
            
            print(f"âš™ï¸  Processing batch {batch_count} with {len(batch)} messages...")
            
            for i, message in enumerate(batch):
                try:
                    transformed_message = self.transform_single_message(message)
                    transformed_batch.append(transformed_message)
                    
                    print(f"   âœ… Transformed message {i+1}: {transformed_message['serviceName']} | {transformed_message['url']}")
                    
                except Exception as e:
                    print(f"   âŒ Error transforming message {i+1}: {e}")
                    # Continue processing other messages
                    continue
            
            if transformed_batch:
                print(f"ðŸ“¦ Yielding transformed batch {batch_count} with {len(transformed_batch)} messages")
                yield transformed_batch
            else:
                print(f"âš ï¸  Batch {batch_count} yielded no valid transformations")
        
        print("âœ… Batch transformation completed!")

    def apply_in_flink(self, t_env, from_table: str) -> str:
        """Not implemented for batch transformer
        
        This transformer is designed for batch processing, not Flink streaming.
        Use Flink*Transform classes for Flink streaming pipelines.
        """
        raise NotImplementedError("Sample data transformer is for batch processing only")